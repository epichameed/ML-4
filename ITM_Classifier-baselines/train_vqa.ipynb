{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Question Answering Training\n",
    "\n",
    "This notebook runs the VQA training pipeline on Google Colab with GPU acceleration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment\n",
    "\n",
    "First, let's install the required dependencies with compatible versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Remove all potentially conflicting packages\n",
    "!pip uninstall -y torch torchvision torchaudio numpy transformers sentence-transformers timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install base dependencies first\n",
    "!pip install numpy==1.24.3\n",
    "!pip install packaging==23.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install PyTorch ecosystem\n",
    "!pip install torch==2.0.0 torchvision==0.15.0 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install transformers and related packages\n",
    "!pip install transformers==4.28.0\n",
    "!pip install sentence-transformers==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install remaining dependencies\n",
    "!pip install timm==0.6.12 \\\n",
    "            stable-baselines3==2.0.0 \\\n",
    "            opencv-python==4.7.0 \\\n",
    "            pillow==9.4.0 \\\n",
    "            wandb==0.15.0 \\\n",
    "            tqdm==4.65.0 \\\n",
    "            matplotlib==3.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Restart the runtime to ensure clean environment\n",
    "print(\"Please restart the runtime now (Runtime -> Restart runtime)\")\n",
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verify Environment\n",
    "\n",
    "After restarting the runtime, run this cell to verify all packages are properly installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(\"Checking package versions:\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Torchvision: {torchvision.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Transformers: {transformers.__version__}\")\n",
    "\n",
    "print(\"\\nChecking CUDA:\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "print(\"\\nTesting transformers:\")\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "print(\"Transformers test successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/YOUR_USERNAME/ML-4.git\n",
    "%cd ML-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup Data\n",
    "\n",
    "Mount Google Drive and set up data directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "# Create symbolic links to your data\n",
    "!ln -s /content/gdrive/MyDrive/path_to_your_data/visual7w-images ITM_Classifier-baselines/visual7w-images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configure WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import wandb\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "!python ITM_Classifier-baselines/train_vqa_colab.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Monitor Results\n",
    "\n",
    "The training progress can be monitored in:\n",
    "1. The output above\n",
    "2. The WandB dashboard\n",
    "3. Saved models will be in your Google Drive under 'ML4_models/'\n",
    "\n",
    "Note: If you encounter any errors after installing dependencies:\n",
    "1. Restart the runtime\n",
    "2. Run all cells from the beginning in order\n",
    "3. Make sure the version verification cell passes before proceeding"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "VQA Training",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
